{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "195a6b51-d35c-4781-a903-300ce6e20906",
   "metadata": {},
   "source": [
    "## Population decoder analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dbed08-97b9-40fd-be27-4a3478ed3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc0c8ec-f082-4e58-ac7c-a11b5223450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env NBANK_REGISTRY https://gracula.psyc.virginia.edu/neurobank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd83f2-9013-4a3f-8a1c-071033a2bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dlab import pprox, nbank, spikes, plotting\n",
    "import ewave\n",
    "from scipy.linalg import hankel, toeplitz\n",
    "import samplerate\n",
    "from joblib import Memory\n",
    "from appdirs import user_cache_dir\n",
    "from tqdm import tqdm\n",
    "\n",
    "import graphics_defaults\n",
    "from core import df_extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65633b7d-2d6b-41a8-91ef-3911331ee65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib to cache gammatone spectrogram calculations\n",
    "_cache_dir = user_cache_dir(\"preconstruct\", \"melizalab\")\n",
    "_mem = Memory(_cache_dir, verbose=0)\n",
    "_cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e031faff-e425-4c0c-8906-397ba7a5529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_sampling_rate = 20000 # Hz\n",
    "desired_time_step = 0.0025 # s\n",
    "spectrogram_params = {\n",
    "    \"window_time\": 0.005,\n",
    "    \"channels\": 40,\n",
    "    \"f_min\": 1000,\n",
    "    \"f_max\": 8500,\n",
    "}\n",
    "spectrogram_compression = 0.01\n",
    "decoder_window = (0.0, 0.2)  # s\n",
    "n_basis = 20\n",
    "linearity_factor = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0c1caf-defb-41a0-9f9d-6b140c2e9370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_spectrograms_cor(actual: np.ndarray, predicted: np.ndarray) -> float:\n",
    "    \"\"\"Compare two spectrograms using correlation coefficient across the entire stimulus\"\"\"\n",
    "    cc = np.corrcoef(actual.flat, predicted.flat)\n",
    "    return cc[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd5b64-a47b-407e-8880-5637695c1300",
   "metadata": {},
   "source": [
    "## Load neural responses\n",
    "\n",
    "Choose your own adventure here - run either the first cell to analyze all the CR or PR units, or the second cell to analyze all the units from a single site. For testing, recommend using the second cell and picking one of the sites. For Figure 6, we generate the population raster using the first cell with `site_name` set to `cr_units`, and the decoded stimuli are generated with `site_name` as `cr_units` or `pr_units`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b865549-35be-44cc-9565-5b89648c33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# units from a file\n",
    "pprox_dir = None\n",
    "site_name = \"cr_units\"\n",
    "unit_file = Path(f\"../build/{site_name}.txt\")\n",
    "unit_names = [line.strip() for line in open(unit_file, \"rt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212cead1-21b7-472d-922f-c3bddb14c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the units for a site\n",
    "site_name = \"C42_4_1\"\n",
    "site_name = \"R227_3_1\"  # not very invariant\n",
    "site_name = \"C41_5_1\"   # okay performance with few units\n",
    "site_name = \"C45_4_1\"   # poor performance with a lot of units\n",
    "site_name = \"C104_4_1\"  # good performance with few units\n",
    "site_name = \"C29_1_1\"   # good performance with a lot of units\n",
    "pprox_dir = None\n",
    "unit_names = [record[\"name\"] for record in nbank.search(nbank.default_registry, name=site_name, dtype=\"spikes-pprox\")]                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b630661-f851-46cf-8016-51c7d4815bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials = []\n",
    "for unit_name, pprox_file in tqdm(nbank.find_resources(*unit_names, alt_base=pprox_dir), total=len(unit_names)):\n",
    "    # this will raise an error if the file was not found\n",
    "    pprox_data = json.loads(pprox_file.read_text())\n",
    "    # only clean stimuli\n",
    "    all_trials.extend(trial | {\"unit\": unit_name} for trial in pprox_data[\"pprox\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05884d0-f7fd-484d-9432-259cbc9410d5",
   "metadata": {},
   "source": [
    "### Split up the trials by motif\n",
    "\n",
    "Stimuli comprise sequences of 10 motifs with order counterbalanced using a latin square to average out order effects and ensure each motif is presented against a different segment of the background. These cells split the long responses into their component motifs to generate a big pandas dataframe with one row per unit/motif/trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08289d86-4659-4c80-8f67-13f23ba50c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotifSplitter:\n",
    "    \n",
    "    def __init__(self, resource_ids):\n",
    "        self.stim_info = {}\n",
    "        for result in nbank.describe_many(nbank.default_registry, *stim_names):\n",
    "            metadata = result[\"metadata\"]\n",
    "            metadata[\"foreground\"] = metadata[\"foreground\"].split(\"-\")\n",
    "            self.stim_info[result[\"name\"]] = pd.DataFrame(metadata)\n",
    "\n",
    "    def __call__(self, resource_id: str) -> pd.DataFrame:\n",
    "        return self.stim_info[resource_id]\n",
    "\n",
    "    \n",
    "stim_names = {trial[\"stimulus\"][\"name\"] for trial in all_trials}\n",
    "splitter = MotifSplitter(stim_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfcc5f0-4124-45a2-85ab-e99e60aa63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = []\n",
    "for trial in tqdm(all_trials):\n",
    "    trial_split = pprox.split_trial(trial, splitter)\n",
    "    trial_split[\"unit\"] = trial[\"unit\"]\n",
    "    recording.append(trial_split)\n",
    "recording = (\n",
    "    pd.concat(recording)\n",
    "    .drop(columns=[\"foreground-dBFS\", \"background\"])\n",
    "    .rename(columns={\"foreground\": \"stimulus\"})\n",
    "    .set_index([\"background-dBFS\",\"unit\", \"stimulus\"]).sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2502a776-e657-4301-8239-c1eda7adcea9",
   "metadata": {},
   "source": [
    "## Load stimuli\n",
    "\n",
    "Load the waveforms and compute spectrograms for the stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c5a4ff-b40a-4aad-8992-40743145d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_names = recording.index.get_level_values(\"stimulus\").unique()\n",
    "example_stim = stim_names[0]\n",
    "stimuli = []\n",
    "for stim_name, stim_path in nbank.find_resources(*stim_names):\n",
    "    with ewave.open(stim_path, \"r\") as fp:\n",
    "        samples = ewave.rescale(fp.read(), \"f\")\n",
    "        resampled = samplerate.resample(samples, 1.0 * desired_sampling_rate / fp.sampling_rate, \"sinc_best\")\n",
    "        stimuli.append({\"stimulus\": stim_name, \"samples\": resampled, \"sample_rate\":  desired_sampling_rate})\n",
    "\n",
    "stim_data = pd.DataFrame.from_records(stimuli).set_index(\"stimulus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c0173-903e-418a-ad8b-081518fce3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute gammatone spectrograms\n",
    "from gammatone.gtgram import gtgram, gtgram_strides\n",
    "from gammatone.filters import erb_space\n",
    "\n",
    "def compute_spectrogram(row):\n",
    "    duration = row.samples.size / row.sample_rate\n",
    "    _, hop_samples, _ = gtgram_strides(row.sample_rate, spectrogram_params[\"window_time\"], desired_time_step, row.samples.size)\n",
    "    hop_time = hop_samples / row.sample_rate\n",
    "    # this calculation is cached\n",
    "    spectrogram = _mem.cache(gtgram)(row.samples, row.sample_rate, hop_time=desired_time_step, **spectrogram_params)\n",
    "    _, nframes = spectrogram.shape\n",
    "    spectrogram = np.log10(spectrogram + spectrogram_compression) - np.log10(spectrogram_compression)\n",
    "    index = np.arange(0.0, duration, hop_time)[:nframes]\n",
    "    columns = erb_space(spectrogram_params[\"f_min\"], spectrogram_params[\"f_max\"], spectrogram_params[\"channels\"])[::-1]\n",
    "    return pd.DataFrame(spectrogram.T, columns=columns, index=index).rename_axis(index=\"time\", columns=\"frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e791cc-0133-45e6-b4d1-f382703558e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stims_processed = pd.concat({index: compute_spectrogram(row) for index, row in stim_data.iterrows()}, names=(\"stimulus\", \"time\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b98573-8057-4044-8ac0-d775409aefb3",
   "metadata": {},
   "source": [
    "#### Plot population responses\n",
    "\n",
    "This is used to generate Figure 6A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639eb358-f5a8-4ff6-b1b6-c0fe902d7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can color-code by cell type, not used\n",
    "spike_type_colors = {\"wide\": \"#70549B\", \"narrow\": \"#FF7F0E\"}\n",
    "feature_file = Path(\"..\") / \"build\" / \"mean_spike_features.csv\"\n",
    "features = pd.read_csv(feature_file)[[\"unit\", \"spike\"]]\n",
    "features[\"site\"] = features.unit.apply(lambda s: \"_\".join(s.split(\"_\")[:-1]))\n",
    "features.set_index(\"unit\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bb63cb-9918-4c83-9914-21d94433ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ace31-e156-4701-bab1-5c9d662086a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_motifs = 2\n",
    "clean_recording = recording.loc[-100]\n",
    "selected_motifs = stim_names[:n_motifs]\n",
    "unit_names = recording.index.get_level_values(\"unit\").unique()\n",
    "n_units = len(unit_names)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=n_motifs, sharex=True, sharey=\"row\", height_ratios=(400, n_units), figsize=(1.75 * n_motifs, 1.8), dpi=450)\n",
    "for col, motif in zip(axes.T, selected_motifs):\n",
    "    spectrogram = stims_processed.loc[motif].T\n",
    "    extent=df_extent(spectrogram)\n",
    "    extent=(extent[0], extent[1], 0, spectrogram.index.size)\n",
    "    col[0].imshow(spectrogram, extent=extent, aspect=\"auto\", origin=\"lower\")\n",
    "    tick_idx = [0, 19, 39]\n",
    "    col[0].set_yticks(tick_idx, [f\"{Y_test.columns[i] / 1000:.0f}\" for i in tick_idx], size=4)\n",
    "    #col[0].tick_params(axis='y', which='both', left=False, right=False, labelleft=True)\n",
    "    col[0].get_xaxis().set_visible(False)\n",
    "    col[0].set_frame_on(False)\n",
    "    motif_trials = clean_recording.xs(motif, level=\"stimulus\") #.join(features, on=\"unit\", how=\"inner\").sort_values([\"site\", \"spike\"])\n",
    "    for i, trial in enumerate(motif_trials.itertuples()):\n",
    "        if isinstance(trial.events, float):\n",
    "            continue\n",
    "        col[1].plot(\n",
    "            trial.events,\n",
    "            [i] * trial.events.size,\n",
    "            color=\"k\", # spike_type_colors[trial.spike],\n",
    "            marker=\"|\",\n",
    "            markeredgewidth=0.1,\n",
    "            markersize=0.15,\n",
    "            linestyle=\"\",\n",
    "        )\n",
    "    col[1].set_xlim(0, df_extent(spectrogram)[1] + decoder_window[1])\n",
    "    col[1].tick_params(axis='both', which='major', labelsize=4)\n",
    "    col[1].tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "    for boundary in (\"left\", \"right\",\"top\"):\n",
    "        col[1].spines[boundary].set_visible(False)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79e4121-1eaf-4bbe-8467-07b38e837e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"../figures/{site_name}_population_responses.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964cd889-d479-4251-9d94-92642d908474",
   "metadata": {},
   "source": [
    "## Pool and bin responses\n",
    "\n",
    "We use trial-averaged firing rates - because we are pooling non-simultaneous recordings, there's not really anything we can learn from single-trial data, and it massively speeds things up to reduce the number of rows by a factor of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42063a3-7da2-4d6e-9f18-dde0d59d380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_spikes(x):\n",
    "    try:\n",
    "        return np.concatenate(x.dropna().values)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def bin_responses(trials):\n",
    "    stim = trials.name\n",
    "    interval_end = trials.interval_end.iloc[0]\n",
    "    stim_bins = stims_processed.loc[stim].index.to_numpy()\n",
    "    time_step = stim_bins[1] - stim_bins[0]\n",
    "    edges = np.concatenate([\n",
    "        stim_bins,\n",
    "        np.arange(stim_bins[-1], interval_end + time_step, time_step)[1:]\n",
    "    ])\n",
    "    rates = np.column_stack(trials.apply(lambda df: np.histogram(df.events, bins=edges)[0] / df.trials, axis=1))\n",
    "    return pd.DataFrame(rates, index=pd.Index(edges[:-1], name=\"time\"), columns=trials.index.get_level_values(0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e17ed5-dcac-4904-bbd3-a75dc29066fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rate_data = (\n",
    "    clean_recording\n",
    "    .groupby([\"unit\", \"stimulus\"])\n",
    "    .agg(\n",
    "        events=pd.NamedAgg(column=\"events\", aggfunc=pool_spikes),\n",
    "        trials=pd.NamedAgg(column=\"events\", aggfunc=len),\n",
    "        interval_end=pd.NamedAgg(column=\"interval_end\", aggfunc=\"max\")\n",
    "    )\n",
    "    .groupby(\"stimulus\")\n",
    "    .apply(bin_responses)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc0270-44c9-445c-982d-271a1949918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=n_motifs, sharex=True, sharey=\"row\", height_ratios=(0.2, 0.4), figsize=(12, 4))\n",
    "for col, motif in zip(axes.T, selected_motifs):\n",
    "    spectrogram = stims_processed.loc[motif].T\n",
    "    col[0].imshow(spectrogram, extent=df_extent(spectrogram), aspect=\"auto\", origin=\"lower\")\n",
    "    col[0].set_yticks([1000, 4000, 8000], [\"1\", \"4\", \"8\"])\n",
    "    col[0].get_xaxis().set_visible(False)\n",
    "    neurogram = clean_rate_data.loc[motif].T\n",
    "    col[1].imshow(neurogram, extent=df_extent(neurogram), origin=\"lower\", aspect=\"auto\", interpolation=\"nearest\", cmap=\"Grays\", vmin=0, vmax=1)\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c0ac3-fee6-41a3-a23d-f0802e6c3963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c32f0b61-cc60-4a85-aa74-10d5f9f24423",
   "metadata": {},
   "source": [
    "## Delay embedding\n",
    "\n",
    "For a decoding model, the responses need to be delay-embedded so that the model can represent the relationship between the stimulus and the neural activity over a window of time around the model. A purely causal model only has positive lags. We use a raised-cosine basis set with bandwidths that increase with temporal distance, so that we have more precision for spikes that come immediately after the stimulus and less for things further out in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69657409-3f37-4cf5-bd08-3846cddfa8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cosine_basis(n_tau: int, n_basis: int, linearity_factor: float=10) -> np.ndarray:\n",
    "    \"\"\"Make a nonlinearly stretched basis consisting of raised cosines\n",
    "\n",
    "    n_tau:  number of time points\n",
    "    n_basis:     number of basis vectors\n",
    "    linearity_vactor:   offset for nonlinear stretching of x axis (larger values -> more linear spacing)\n",
    "    \"\"\"\n",
    "    _min_offset = 1e-20    \n",
    "    first_peak = np.log(linearity_factor + _min_offset)\n",
    "    last_peak = np.log(n_tau * (1 - 1.5 / n_basis) + linearity_factor + _min_offset)\n",
    "    peak_centers = np.linspace(first_peak, last_peak, n_basis)\n",
    "    peak_spacing = (last_peak - first_peak) / (n_basis - 1)\n",
    "    log_domain = np.log(np.arange(n_tau) + linearity_factor + _min_offset)\n",
    "    basis = []\n",
    "    for center in peak_centers:\n",
    "        cos_input = np.clip((log_domain - center) * np.pi / peak_spacing / 2, -np.pi, np.pi)\n",
    "        cos_basis = (np.cos(cos_input) + 1) / 2\n",
    "        basis.append(cos_basis / np.linalg.norm(cos_basis))\n",
    "    # TODO: return dataframe with labeled axes\n",
    "    return np.column_stack(basis)\n",
    "\n",
    "#plt.imshow(make_cosine_basis(60, 20, linearity_factor));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba1c36-483e-40bc-905e-aa215a3d2d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delay_embed_trial(resp):\n",
    "    trial = resp.name\n",
    "    resp = resp.droplevel(0)\n",
    "    stim_bins = stims_processed.loc[trial].index\n",
    "    time_step = stim_bins[1] - stim_bins[0]\n",
    "    lag_range = pd.Index(np.arange(decoder_window[0], decoder_window[1], time_step), name=\"lag\")\n",
    "    # this should be the same for all stims but it's easier to calculate here\n",
    "    basis_matrix = make_cosine_basis(lag_range.size, n_basis, linearity_factor)\n",
    "    def delay_embed_unit(unit):\n",
    "        col = unit.loc[slice(stim_bins[0] - decoder_window[0], stim_bins[-1])]\n",
    "        row = unit.loc[slice(stim_bins[-1], stim_bins[-1] + decoder_window[1])].iloc[:lag_range.size]\n",
    "        lagged = hankel(col, row)\n",
    "        return pd.DataFrame(np.dot(lagged, basis_matrix), index=col.index)\n",
    "        #return pd.DataFrame(lagged, index=col.index, columns=lag_range)\n",
    "    return pd.concat({unit_name: delay_embed_unit(resp[unit_name]) for unit_name in unit_names}, axis=1, names=(\"unit\", \"lag\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d1d50-b97c-49f7-8eb2-81c5fd5dd41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rates_embedded = clean_rate_data.groupby(\"stimulus\").apply(delay_embed_trial)\n",
    "# this is really important to ensure that all rows match in the two dataframes\n",
    "clean_rates_embedded, clean_stims_processed = clean_rates_embedded.align(stims_processed, join='left', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdefcbc8-f209-481d-aa4a-94f05a617a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this assertion should be true if the stimuli were not repeated\n",
    "assert clean_rates_embedded.shape[0] == clean_stims_processed.shape[0], \"dimensions of data don't match\"\n",
    "assert all(clean_rates_embedded.index == clean_stims_processed.index), \"indices of data don't match\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f0cd72-38e7-4714-98d9-bfa1e7ae9c71",
   "metadata": {},
   "source": [
    "#### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2684d6a-ede2-4ae8-877a-60349f153724",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=n_motifs, sharex=True, sharey=\"row\", height_ratios=(0.2, 0.4), figsize=(12, 4))\n",
    "for col, motif in zip(axes.T, selected_motifs):\n",
    "    spectrogram = stims_processed.loc[motif].T\n",
    "    col[0].imshow(spectrogram, extent=df_extent(spectrogram), aspect=\"auto\", origin=\"lower\")\n",
    "    col[0].set_yticks([1000, 4000, 8000], [\"1\", \"4\", \"8\"])\n",
    "    col[0].get_xaxis().set_visible(False)\n",
    "    neurogram = clean_rates_embedded.loc[motif].T\n",
    "    col[1].imshow(neurogram, extent=df_extent(neurogram), origin=\"lower\", aspect=\"auto\")#, vmin=0, vmax=1)\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32033d-328b-449f-82a7-947e53a81556",
   "metadata": {},
   "source": [
    "## Fit decoder model\n",
    "\n",
    "There are a variety of models that can be used for decoding; linear regression is by far the simplest. We need some regularization because k > n, so using ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d10df36-649b-474f-bca4-4b38e8741f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import ShuffleSplit, KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def compare_spectrograms_rmse(actual: np.ndarray, predicted: np.ndarray) -> float:\n",
    "    esq = (actual - predicted)**2\n",
    "    return np.sqrt(esq.sum())\n",
    "\n",
    "def split_by_stimulus(X, Y):\n",
    "    stimuli = X.index.get_level_values(0).unique()\n",
    "    for stimulus in stimuli:\n",
    "        yield (X.drop(stimulus), Y.drop(stimulus), X.loc[stimulus], Y.loc[stimulus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11142c-fdf8-44a0-a2ab-86977f6b6728",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_candidates = np.logspace(-1, 7, 30)\n",
    "\n",
    "ridge = Pipeline([('scaler', StandardScaler()), ('ridge', Ridge(fit_intercept=True))])\n",
    "xval = GridSearchCV(ridge, cv=10, param_grid={\"ridge__alpha\": alpha_candidates}, n_jobs=2)\n",
    "print(f\"  -  Fitting Model: X shape is {clean_rates_embedded.shape}; Y shape is {clean_stims_processed.shape}\")\n",
    "xval.fit(clean_rates_embedded.values, clean_stims_processed.values);"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89981be4-7655-441d-b145-5bfce4738d8a",
   "metadata": {},
   "source": [
    "model_file = Path(\"../build/decoder_model.pkl\")\n",
    "with open(model_file, \"wb\") as fp:\n",
    "    pickle.dump(xval, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07928f73-886a-4b87-b66c-905a4a5454bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(xval.cv_results_)\n",
    "# plt.plot(alpha_candidates, cv_results.mean_test_score, 'o')\n",
    "plt.errorbar(np.log(alpha_candidates), cv_results.mean_test_score, yerr=cv_results.std_test_score, fmt=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f21e3ed-1f70-4b10-ae15-778d589fe5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha_idx = xval.best_index_\n",
    "best_alpha = xval.best_params_[\"ridge__alpha\"]\n",
    "print(f\"Best alpha: {best_alpha}; best score: {xval.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf2664-25cc-4fd4-9d6b-694804a03629",
   "metadata": {},
   "source": [
    "### Test decoding\n",
    "\n",
    "Using the best alpha, iterate through the stimuli, holding each out as test data while fitting the model to the remaining stimuli.\n",
    "\n",
    "Then iterate through the noise levels to generate predictions for responses to clean and noisy stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c188249e-acba-4733-9f67-089428896228",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_stim = stim_names[1]\n",
    "X_train = clean_rates_embedded.drop(example_stim)\n",
    "Y_train = clean_stims_processed.drop(example_stim)\n",
    "X_test = clean_rates_embedded.loc[example_stim]\n",
    "Y_test = clean_stims_processed.loc[example_stim]\n",
    "fitted = ridge.set_params(ridge__alpha=best_alpha).fit(X_train.values, Y_train.values)\n",
    "pred = fitted.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9afd8e-ac06-4734-bc87-6b4506aa6f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(1.6,1.2), dpi=300)\n",
    "extent = df_extent(Y_test.T)\n",
    "axes[0].imshow(Y_test.T, extent=(extent[0], extent[1], 0, Y_test.columns.size), origin=\"lower\", aspect=\"auto\")\n",
    "axes[0].set_title(\"Actual\")\n",
    "axes[1].imshow(pred.T, extent=(extent[0], extent[1], 0, Y_test.columns.size), origin=\"lower\", aspect=\"auto\")\n",
    "axes[1].set_title(\"Decoded\")\n",
    "for ax in axes:\n",
    "    ax.tick_params(axis='y', which='both', left=False, right=False, labelleft=True)\n",
    "    ax.set_yticks([0, 19, 39])\n",
    "    ax.set_yticklabels(f\"{Y_test.columns[i] / 1000:.0f}\" for i in (0, 19, 39))\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbf2b82-80b4-455d-989d-93ab931ebffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"../figures/{site_name}_{example_stim}_decoded.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e3bca4-f369-47d1-9140-3420a51045a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c7476-df7e-499f-907f-df56bd845f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16c7bf-6514-4da7-b051-2b7935a8edcc",
   "metadata": {},
   "source": [
    "### Noise invariance\n",
    "\n",
    "To test for noise invariance, we use the fitted model to decode the responses to motifs embedded in colony noise, then compare to the prediction generated from the response to the clean stimulus. In essense, we're first projecting the response into the 40-dimensional stimulus space and then assessing how much it changes when we add noise. We haven't used the noisy-stimulus data yet so this will also have to be preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b102a1-4037-4a8b-9960-a4dc76f9eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = recording.index.get_level_values(\"background-dBFS\").unique().drop(-100)\n",
    "noise_level = noise_levels[-1]\n",
    "noise_recording = recording.loc[noise_level].xs(example_stim, level=\"stimulus\", drop_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b2e104-f207-416d-a4fa-482e39fe7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_invariance = []\n",
    "fig, axes = plt.subplots(nrows=noise_levels.size + 1, ncols=1, sharex=True, figsize=(1.25,3.2), dpi=300)\n",
    "axes[0].imshow(pred.T, extent=extent, origin=\"lower\", aspect=\"auto\")\n",
    "axes[0].set_ylabel(\"70\", rotation=\"horizontal\")\n",
    "axes[0].tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "for i, noise_level in enumerate(noise_levels, 1):\n",
    "    noise_recording = recording.loc[noise_level].xs(example_stim, level=\"stimulus\", drop_level=False)\n",
    "    noise_rate_data = (\n",
    "        noise_recording\n",
    "        .groupby([\"unit\", \"stimulus\"])\n",
    "        .agg(\n",
    "            events=pd.NamedAgg(column=\"events\", aggfunc=pool_spikes),\n",
    "            trials=pd.NamedAgg(column=\"events\", aggfunc=len),\n",
    "            interval_end=pd.NamedAgg(column=\"interval_end\", aggfunc=\"max\")\n",
    "        )\n",
    "        .groupby(\"stimulus\")\n",
    "        .apply(bin_responses)\n",
    "    )\n",
    "    noise_rates_embedded = noise_rate_data.groupby(\"stimulus\").apply(delay_embed_trial)\n",
    "    # align will also pick out the matching stimulus\n",
    "    noise_rates_embedded, noise_stims_processed = noise_rates_embedded.align(stims_processed, join='left', axis=0)\n",
    "    # this assertion should be true if the stimuli were not repeated\n",
    "    assert noise_rates_embedded.shape[0] == noise_stims_processed.shape[0], \"dimensions of data don't match\"\n",
    "    assert all(noise_rates_embedded.index == noise_stims_processed.index), \"indices of data don't match\"\n",
    "\n",
    "    score_actual = fitted.score(noise_rates_embedded, Y_test)\n",
    "    score_pred_clean = fitted.score(noise_rates_embedded, pred)\n",
    "    pred_noisy = fitted.predict(noise_rates_embedded)\n",
    "    pred_invariance.append({\n",
    "        \"background-dBFS\": noise_level,\n",
    "        \"score_actual\": score_actual,\n",
    "        \"cor_actual\": compare_spectrograms_cor(Y_test.values, pred_noisy),\n",
    "        \"score_pred_clean\": score_pred_clean,\n",
    "        \"cor_pred_clean\": compare_spectrograms_cor(pred, pred_noisy)\n",
    "    })\n",
    "    axes[i].imshow(pred_noisy.T, extent=extent, origin=\"lower\", aspect=\"auto\")\n",
    "    axes[i].set_ylabel(f\"{-30 - noise_level}\", rotation=\"horizontal\")\n",
    "    axes[i].tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "for ax in axes[:-1]:\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7f792-1bbb-4951-8bb3-c1e2fbb7efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"../figures/{site_name}_{example_stim}_noise_invariance.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8bed44-0ade-4cd8-a311-5915ba62be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(pred_invariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63a96d-e00f-4531-83c0-fcc9f319412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted.score(noise_rates_embedded, pred_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f79f1-bed1-4160-9bdd-5180d229262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76298885-e91e-40fa-a0ae-893e424a675e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cr-pr-adults",
   "language": "python",
   "name": "cr-pr-adults"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
